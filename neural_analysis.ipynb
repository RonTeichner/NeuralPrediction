{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Prediction Analysis\n",
    "## Electrophysiological Data Analysis from Multi-Electrode Array Recordings\n",
    "\n",
    "This notebook analyzes neural spike data from soma recordings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Load Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "# Load configuration\n",
    "with open('config.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use(config['plotting']['style'])\n",
    "sns.set_palette('husl')\n",
    "\n",
    "print(\"Configuration loaded successfully!\")\n",
    "print(f\"Dataset path: {config['data']['dataset_path']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data_path = config['data']['dataset_path']\n",
    "df = pd.read_csv(data_path, sep='\\t')\n",
    "\n",
    "print(f\"Dataset loaded: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
    "print(f\"\\nColumn names: {list(df.columns)}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Overview and Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics\n",
    "print(\"=\" * 60)\n",
    "print(\"DATASET SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nTime range: {df['time'].min():.6f} to {df['time'].max():.6f} seconds\")\n",
    "print(f\"Duration: {df['time'].max() - df['time'].min():.2f} seconds\")\n",
    "\n",
    "print(f\"\\nNumber of unique experiments: {df['experiment'].nunique()}\")\n",
    "print(f\"Experiments: {df['experiment'].unique()}\")\n",
    "\n",
    "print(f\"\\nNumber of unique channels: {df['channel'].nunique()}\")\n",
    "print(f\"Channels: {sorted(df['channel'].unique())}\")\n",
    "\n",
    "print(f\"\\nNumber of unique electrodes: {df['electrode'].nunique()}\")\n",
    "\n",
    "print(f\"\\nAmplitude statistics:\")\n",
    "print(df['amplitude'].describe())\n",
    "\n",
    "print(f\"\\nSpatial range:\")\n",
    "print(f\"  X: {df['x'].min()} to {df['x'].max()}\")\n",
    "print(f\"  Y: {df['y'].min()} to {df['y'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"\\nMissing values per column:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Data types\n",
    "print(\"\\nData types:\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Channel-wise Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of recordings per channel\n",
    "channel_counts = df['channel'].value_counts().sort_index()\n",
    "\n",
    "print(\"Recordings per channel:\")\n",
    "print(channel_counts)\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=tuple(config['plotting']['figure_size']))\n",
    "channel_counts.plot(kind='bar', ax=ax)\n",
    "ax.set_xlabel('Channel')\n",
    "ax.set_ylabel('Number of Recordings')\n",
    "ax.set_title('Distribution of Recordings Across Channels')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amplitude statistics per channel\n",
    "print(\"\\nAmplitude statistics per channel:\")\n",
    "channel_stats = df.groupby('channel')['amplitude'].agg(['mean', 'std', 'min', 'max', 'count'])\n",
    "print(channel_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Spike Detection Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect spikes based on threshold\n",
    "spike_threshold = config['analysis']['spike_threshold']\n",
    "df['is_spike'] = np.abs(df['amplitude']) > spike_threshold\n",
    "\n",
    "print(f\"Spike detection threshold: {spike_threshold}\")\n",
    "print(f\"Total spikes detected: {df['is_spike'].sum()}\")\n",
    "print(f\"Percentage of recordings with spikes: {100 * df['is_spike'].sum() / len(df):.2f}%\")\n",
    "\n",
    "# Spikes per channel\n",
    "spikes_per_channel = df[df['is_spike']].groupby('channel').size()\n",
    "print(f\"\\nSpikes per channel:\")\n",
    "print(spikes_per_channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot spike distribution\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# 1. Spikes per channel\n",
    "spikes_per_channel.plot(kind='bar', ax=axes[0, 0], color='coral')\n",
    "axes[0, 0].set_xlabel('Channel')\n",
    "axes[0, 0].set_ylabel('Number of Spikes')\n",
    "axes[0, 0].set_title('Spike Count per Channel')\n",
    "\n",
    "# 2. Spike amplitude distribution\n",
    "spike_amplitudes = df[df['is_spike']]['amplitude']\n",
    "axes[0, 1].hist(spike_amplitudes, bins=50, color='skyblue', edgecolor='black')\n",
    "axes[0, 1].set_xlabel('Amplitude')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "axes[0, 1].set_title('Distribution of Spike Amplitudes')\n",
    "\n",
    "# 3. Spike times histogram\n",
    "spike_times = df[df['is_spike']]['time']\n",
    "axes[1, 0].hist(spike_times, bins=50, color='lightgreen', edgecolor='black')\n",
    "axes[1, 0].set_xlabel('Time (s)')\n",
    "axes[1, 0].set_ylabel('Frequency')\n",
    "axes[1, 0].set_title('Temporal Distribution of Spikes')\n",
    "\n",
    "# 4. Spikes per experiment\n",
    "spikes_per_exp = df[df['is_spike']].groupby('experiment').size()\n",
    "spikes_per_exp.plot(kind='barh', ax=axes[1, 1], color='plum')\n",
    "axes[1, 1].set_xlabel('Number of Spikes')\n",
    "axes[1, 1].set_ylabel('Experiment')\n",
    "axes[1, 1].set_title('Spike Count per Experiment')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Temporal Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot amplitude over time for each channel\n",
    "fig, axes = plt.subplots(len(df['channel'].unique()), 1, \n",
    "                         figsize=(15, 3 * len(df['channel'].unique())), \n",
    "                         sharex=True)\n",
    "\n",
    "if len(df['channel'].unique()) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for idx, channel in enumerate(sorted(df['channel'].unique())):\n",
    "    channel_data = df[df['channel'] == channel]\n",
    "    axes[idx].plot(channel_data['time'], channel_data['amplitude'], \n",
    "                   linewidth=0.5, alpha=0.7)\n",
    "    axes[idx].axhline(y=-spike_threshold, color='r', linestyle='--', \n",
    "                      linewidth=1, label=f'Threshold: -{spike_threshold}')\n",
    "    axes[idx].axhline(y=spike_threshold, color='r', linestyle='--', linewidth=1)\n",
    "    axes[idx].set_ylabel('Amplitude')\n",
    "    axes[idx].set_title(f'Channel {int(channel)}')\n",
    "    axes[idx].legend(loc='upper right')\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "\n",
    "axes[-1].set_xlabel('Time (s)')\n",
    "plt.suptitle('Neural Activity Over Time by Channel', y=1.001, fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Spatial Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spatial distribution of electrodes\n",
    "electrode_locations = df.groupby('electrode')[['x', 'y']].first()\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# 1. All electrode locations\n",
    "for channel in df['channel'].unique():\n",
    "    channel_electrodes = df[df['channel'] == channel][['x', 'y', 'electrode']].drop_duplicates()\n",
    "    axes[0].scatter(channel_electrodes['x'], channel_electrodes['y'], \n",
    "                   s=100, alpha=0.6, label=f'Channel {int(channel)}')\n",
    "\n",
    "axes[0].set_xlabel('X Coordinate')\n",
    "axes[0].set_ylabel('Y Coordinate')\n",
    "axes[0].set_title('Spatial Distribution of Electrodes by Channel')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Spike locations (heatmap)\n",
    "spike_data = df[df['is_spike']]\n",
    "if len(spike_data) > 0:\n",
    "    scatter = axes[1].scatter(spike_data['x'], spike_data['y'], \n",
    "                             c=np.abs(spike_data['amplitude']), \n",
    "                             s=50, alpha=0.6, cmap='hot')\n",
    "    axes[1].set_xlabel('X Coordinate')\n",
    "    axes[1].set_ylabel('Y Coordinate')\n",
    "    axes[1].set_title('Spatial Distribution of Spikes (colored by amplitude)')\n",
    "    plt.colorbar(scatter, ax=axes[1], label='Absolute Amplitude')\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Inter-Spike Interval (ISI) Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate ISI for each channel\n",
    "fig, axes = plt.subplots(len(df['channel'].unique()), 1, \n",
    "                         figsize=(12, 4 * len(df['channel'].unique())))\n",
    "\n",
    "if len(df['channel'].unique()) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for idx, channel in enumerate(sorted(df['channel'].unique())):\n",
    "    channel_spikes = df[(df['channel'] == channel) & (df['is_spike'])]['time'].values\n",
    "    \n",
    "    if len(channel_spikes) > 1:\n",
    "        isi = np.diff(channel_spikes)\n",
    "        \n",
    "        axes[idx].hist(isi, bins=50, color='teal', edgecolor='black', alpha=0.7)\n",
    "        axes[idx].set_xlabel('Inter-Spike Interval (s)')\n",
    "        axes[idx].set_ylabel('Frequency')\n",
    "        axes[idx].set_title(f'Channel {int(channel)} - ISI Distribution (Mean: {np.mean(isi):.4f}s)')\n",
    "        axes[idx].grid(True, alpha=0.3)\n",
    "    else:\n",
    "        axes[idx].text(0.5, 0.5, 'Insufficient spike data', \n",
    "                      ha='center', va='center', transform=axes[idx].transAxes)\n",
    "        axes[idx].set_title(f'Channel {int(channel)} - ISI Distribution')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Experiment Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare experiments\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Amplitude distribution by experiment\n",
    "for exp in df['experiment'].unique():\n",
    "    exp_data = df[df['experiment'] == exp]['amplitude']\n",
    "    axes[0].hist(exp_data, bins=50, alpha=0.5, label=exp, edgecolor='black')\n",
    "\n",
    "axes[0].set_xlabel('Amplitude')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title('Amplitude Distribution by Experiment')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Recording counts by experiment\n",
    "exp_counts = df.groupby('experiment').size()\n",
    "exp_counts.plot(kind='barh', ax=axes[1], color='mediumpurple')\n",
    "axes[1].set_xlabel('Number of Recordings')\n",
    "axes[1].set_ylabel('Experiment')\n",
    "axes[1].set_title('Recording Count by Experiment')\n",
    "axes[1].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix of numerical features\n",
    "numerical_cols = ['time', 'channel', 'amplitude', 'electrode', 'x', 'y']\n",
    "corr_matrix = df[numerical_cols].corr()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, fmt='.3f', cmap='coolwarm', \n",
    "            center=0, square=True, ax=ax, cbar_kws={'label': 'Correlation'})\n",
    "ax.set_title('Correlation Matrix of Numerical Features')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"NEURAL PREDICTION ANALYSIS - SUMMARY REPORT\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nüìä Dataset: {config['data']['dataset_path']}\")\n",
    "print(f\"   Total recordings: {len(df):,}\")\n",
    "print(f\"   Time span: {df['time'].max() - df['time'].min():.2f} seconds\")\n",
    "\n",
    "print(f\"\\nüß™ Experiments: {df['experiment'].nunique()}\")\n",
    "for exp in df['experiment'].unique():\n",
    "    count = len(df[df['experiment'] == exp])\n",
    "    print(f\"   - {exp}: {count:,} recordings\")\n",
    "\n",
    "print(f\"\\nüì° Channels: {df['channel'].nunique()}\")\n",
    "for channel in sorted(df['channel'].unique()):\n",
    "    count = len(df[df['channel'] == channel])\n",
    "    spikes = df[(df['channel'] == channel) & (df['is_spike'])].shape[0]\n",
    "    print(f\"   - Channel {int(channel)}: {count:,} recordings, {spikes} spikes\")\n",
    "\n",
    "print(f\"\\n‚ö° Spike Analysis:\")\n",
    "print(f\"   Threshold: ¬±{spike_threshold}\")\n",
    "print(f\"   Total spikes: {df['is_spike'].sum():,}\")\n",
    "print(f\"   Spike rate: {df['is_spike'].sum() / (df['time'].max() - df['time'].min()):.2f} spikes/second\")\n",
    "\n",
    "print(f\"\\nüìà Amplitude Statistics:\")\n",
    "print(f\"   Mean: {df['amplitude'].mean():.3f}\")\n",
    "print(f\"   Std: {df['amplitude'].std():.3f}\")\n",
    "print(f\"   Min: {df['amplitude'].min():.3f}\")\n",
    "print(f\"   Max: {df['amplitude'].max():.3f}\")\n",
    "\n",
    "print(f\"\\nüó∫Ô∏è Spatial Coverage:\")\n",
    "print(f\"   X range: {df['x'].min()} - {df['x'].max()}\")\n",
    "print(f\"   Y range: {df['y'].min()} - {df['y'].max()}\")\n",
    "print(f\"   Unique electrodes: {df['electrode'].nunique()}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}